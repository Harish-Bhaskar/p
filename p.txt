Program 1
import csv
a=[]
with open('enjoysport.csv','r') as csvfile:
    for row in csv.reader(csvfile): 
        a.append(row)
    print(a)

print("\n The total number of training instances are: ",len(a))

num_attribute = len(a[0])-1
print("\n the initial hypothesis is:")
hypothesis = ['0']*num_attributeab
print(hypothesis)

for i in range(0, len(a)):
    if a[i][num_attribute] == 'yes':
        for j in range(0, num_attribute):
            if hypothesis[j]=='0' or hypothesis[j] ==a[i][j]:
                hypothesis[j] = a[i][j]
            else: 
                hypothesis[j]='?'
                
        print('\n The hypothesis for the training instance {} is: \n'.format(i+1), hypothesis)
                
print("\n The Maximally specific hypothesis for the training instance is")
print(hypothesis)

Program 2
import numpy as np
import pandas as pd

data = pd.read_csv('enjoysport.csv')
concepts = np.array(data.iloc[:,0:-1])
print(concepts)
target = np.array(data.iloc[:,-1])
print(target)
def learn (concepts , target):
    
    specific_h = concepts[0].copy()
    print("initilization of specific_h and general_h")
    print(specific_h)
    general_h = [['?' for i in range(len(specific_h))] for i in range(len(specific_h ))]
    print (general_h)
    
    for i , h in enumerate(concepts):
        print("for loop starts")
        if target[i] == "yes":
            print("If instance is positive")
            for x in range (len(specific_h)):
                if h[x]!= specific_h[x]:
                    specific_h[x] = '?'
                    general_h[x][x] = '?'
                    
        if target[i] == "no":
            print("If instance is Negative")
            for x in range(len(specific_h)):
                if h[x]!= specific_h[x]:
                    general_h[x][x] = specific_h[x]
                else:
                    general_h[x][x] = '?'
        
        print('steps of candidate Eliminination Algorithm',i+1)
        print(specific_h)
        print(general_h)
        print('\n')
        print('\n')
        
    indices = [i for i,val in enumerate(general_h) if val == ['?','?','?','?','?','?']]
    for i in indices:
        general_h.remove(['?','?','?','?','?','?'])
    return specific_h,general_h

s_final , g_final = learn(concepts,target)

print('Final specific_h:', s_final , sep ="\n")
print('Final general_h:', g_final , sep ="\n")

Program 3
import math
import csv
def load_csv(filename):
    lines=csv.reader(open(filename,"r"));
    dataset = list(lines)
    headers = dataset.pop(0)
    return dataset,headers

class Node:
    def __init__(self,attribute):
        self.attribute=attribute
        self.children=[]
        self.answer=""
        
def subtables(data,col,delete):
    dic={}
    coldata=[row[col] for row in data]
    attr=list(set(coldata))
    
    counts=[0]*len(attr)
    r=len(data)
    c=len(data[0])
    for x in range(len(attr)):
        for y in range(r):
            if data[y][col]==attr[x]:
                counts[x]+=1
                
    for x in range(len(attr)):
        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]
        pos=0
        for y in range(r):
            if data[y][col]==attr[x]:
                if delete:
                    del data[y][col]
                dic[attr[x]][pos]=data[y]
                pos+=1
    return attr,dic
                       

def entropy(S):
    attr=list(set(S))
    if len(attr)==1:
        return 0
                       
    counts=[0,0]
    for i in range(2):
        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)
                       
    sums=0
    for cnt in counts:
        sums+=-1*cnt*math.log(cnt,2)
    return sums
                       
def compute_gain(data,col):
    attr,dic = subtables(data,col,delete=False)
                       
    total_size=len(data)
    entropies=[0]*len(attr)
    ratio=[0]*len(attr)
                       
    total_entropy=entropy([row[-1] for row in data])
    for x in range(len(attr)):
        ratio[x]=len(dic[attr[x]])/(total_size*1.0)
        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])
        total_entropy-=ratio[x]*entropies[x]
    return total_entropy
                       
def build_tree(data,features):
    lastcol=[row[-1] for row in data]
    if(len(set(lastcol)))==1:
        node=Node("")
        node.answer=lastcol[0]
        return node
                       
    n=len(data[0])-1
    gains=[0]*n
    for col in range(n):
        gains[col]=compute_gain(data,col)
    split=gains.index(max(gains))
    node=Node(features[split])
    fea = features[:split]+features[split+1:]
                       
    attr,dic=subtables(data,split,delete=True)
                       
    for x in range(len(attr)):
        child=build_tree(dic[attr[x]],fea)
        node.children.append((attr[x],child))
    return node
                       
def print_tree(node,level):
    if node.answer!="":
        print("  "*level,node.answer)
        return
                       
    print("  "*level,node.attribute)
    for value,n in node.children:
        print(" "*(level+1),value)
        print_tree(n,level+2)
                       
def classify(node,x_test,features):
    if node.answer!="":
        print(node.answer)
        return
    pos=features.index(node.attribute)
    for value, n in node.children:
        if x_test[pos]==value:
            classify(n,x_test,features)
                       
dataset,features=load_csv("id3.csv")
node1=build_tree(dataset,features)
                       
print("the decision tree for the dataset using ID3 algorithm is")
print_tree(node1,0)
testdata,features=load_csv("id3_test.csv")
for xtest in testdata:
    print("the test instance:",xtest)
    print("the label for test instance:",end=" ")
    classify(node1,xtest,features)

Program 4

import numpy as np
X=np.array(([2,9],[1,5],[3,6]),dtype=float)
y=np.array(([92],[86],[89]),dtype=float)

X=X/np.amax(X,axis=0)
y=y/100

def sigmoid(x):
    return 1/(1+np.exp(-x))

def derivatives_sigmoid(x):
    return x*(1-x)


epoch=5000
lr=0.1

inputlayer_neurons=2
hiddenlayer_neurons=3
output_neurons=1

wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))
bh=np.random.uniform(size=(1,hiddenlayer_neurons))

wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))

for i in range(epoch):
    hinp1=np.dot(X,wh)
    hinp=hinp1+bh
    hlayer_act=sigmoid(hinp)
    
    outinp1=np.dot(hlayer_act,wout)
    outinp=outinp1+bout
    output=sigmoid(outinp)
    
    EO=y-output
    outgrad=derivatives_sigmoid(output)
    d_output=EO*outgrad
    EH=d_output.dot(wout.T)
    
    hiddengrad=derivatives_sigmoid(hlayer_act)
    d_hiddenlayer=EH*hiddengrad
    
wout+=hlayer_act.T.dot(d_output)*lr
wh+=X.T.dot(d_hiddenlayer)*lr

print("Input:\n"+str(X))
print("Actual Output:\n"+str(y))
print("Predicted Output:\n",output)

Program 5
import csv
import random
import math
def loadcsv(filename):
    lines = csv.reader(open(filename, "r"));
    dataset = list(lines)
    for i in range(len(dataset)):
        dataset[i] = [float(x) for x in dataset[i]]
    return dataset

def splitdataset(dataset, splitratio):
    trainsize = int(len(dataset) * splitratio);
    trainset = []
    copy = list(dataset);
    while len(trainset) < trainsize:
        index = random.randrange(len(copy));
        trainset.append(copy.pop(index))
    return [trainset, copy]

def separatebyclass(dataset):
    separated = {} 
    for i in range(len(dataset)):
        vector = dataset[i]
        if (vector[-1] not in separated):
            separated[vector[-1]] = []
        separated[vector[-1]].append(vector)
    return separated

def mean(numbers):
    return sum(numbers)/float(len(numbers))

def stdev(numbers):
    avg = mean(numbers)
    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)
    return math.sqrt(variance)

def summarize(dataset): 
    summaries= [(mean(attribute),stdev(attribute)) for attribute in zip(*dataset)];
    del summaries[-1] 
    return summaries

def summarizebyclass(dataset):
    separated = separatebyclass(dataset);
    summaries = {}
    for classvalue, instances in separated.items():
        summaries[classvalue] = summarize(instances)
    return summaries

def calculateprobability(x, mean, stdev):
    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))
    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent

def calculateclassprobabilities(summaries, inputvector):
    probabilities = {}
    for classvalue, classsummaries in summaries.items():
        probabilities[classvalue] = 1
        for i in range(len(classsummaries)):
            mean, stdev = classsummaries[i] 
            x = inputvector[i] 
            probabilities[classvalue] *=calculateprobability(x, mean, stdev);
    return probabilities

def predict(summaries, inputvector): 
    probabilities = calculateclassprobabilities(summaries,inputvector)
    bestLabel, bestProb = None, -1
    for classvalue, probability in probabilities.items():
        if bestLabel is None or probability > bestProb:
            bestProb = probability
            bestLabel = classvalue
    return bestLabel

def getpredictions(summaries, testset):
    predictions = []
    for i in range(len(testset)):
        result = predict(summaries, testset[i])
        predictions.append(result)
    return predictions

def getaccuracy(testset, predictions):
    correct = 0
    for i in range(len(testset)):
        if testset[i][-1] == predictions[i]:
            correct += 1
    return (correct/float(len(testset))) * 100.0

def main():
    filename = 'naivedata.csv'
    splitratio = 0.67
    dataset = loadcsv(filename);
    trainingset, testset = splitdataset(dataset, splitratio)
    print('Split {0} rows into train={1} and test={2}rows'.format(len(dataset), len(trainingset), len(testset)))
    summaries = summarizebyclass(trainingset);
    predictions = getpredictions(summaries, testset) 
    accuracy = getaccuracy(testset, predictions)
    print('Accuracy of the classifier is :{0}%'.format(accuracy))

main()


Altenative

import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.naive_bayes import GaussianNB 
from sklearn import metrics

df=pd.read_csv("pima_indian.csv")
feature_col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness','insulin','bmi','diab_pred','age']
predicted_class_names=['diabetes'] 

X=df[feature_col_names].values
y=df[predicted_class_names].values

xtrain, xtest, ytrain, ytest=train_test_split(X,y,test_size=0.33)
print ('\n the total number of Training Data:', ytrain.shape) 
print ('\n the total number of Test Data :',ytest.shape)

clf=GaussianNB().fit(xtrain, ytrain.ravel())
predicted=clf.predict(xtest) 
predictTestData= clf.predict([[6,148,72,35,0,33.6,0.627,50]])

print("\n Confusion matrix") 
print(metrics.confusion_matrix(ytest, predicted))
print("\n Accuracy of the classifier is", metrics.accuracy_score(ytest, predicted))
print('\n The value of Precision', metrics.precision_score(ytest, predicted))
print("\n The value of Recall", metrics.recall_score(ytest, predicted))
print("Predicted Value for individual Test Data;", predictTestData)
